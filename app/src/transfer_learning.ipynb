{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import clone_model\n",
    "import mlflow\n",
    "from utils import plot_loss_acc\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('../data/x_train.npy', allow_pickle=True)\n",
    "x_test = np.load('../data/x_test.npy', allow_pickle=True)\n",
    "y_train = np.load('../data/y_train.npy', allow_pickle=True)\n",
    "y_test = np.load('../data/y_test.npy', allow_pickle=True)\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "out_size = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Res-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "head_model = base_model.output\n",
    "head_model = GlobalAveragePooling2D(name=\"out_pool\")(head_model)\n",
    "head_model = Dense(out_size, activation=\"softmax\", name=\"out_layer\")(head_model)\n",
    "\n",
    "model = Model(base_model.input, head_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"resnet\"):\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 20\n",
    "    VAL_SPLIT = 0.1\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VAL_SPLIT)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    print(loss, accuracy)\n",
    "\n",
    "    params = {\"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE}\n",
    "    metrics = {\"test_loss\": loss, \"test_acc\": accuracy}\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    for idx in range(len(history.history[\"loss\"])):\n",
    "        mlflow.log_metrics({'train_loss': history.history[\"loss\"][idx], 'train_acc': history.history[\"accuracy\"][idx], \n",
    "                           'val_loss': history.history[\"val_loss\"][idx], 'val_acc': history.history[\"val_accuracy\"][idx]}, step=idx+1)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"resnet-data-aug\"):\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 15\n",
    "    VAL_SPLIT = 0.1\n",
    "    TRAIN_BATCH = 64\n",
    "    VAL_BATCH = 64\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20, horizontal_flip=True, vertical_flip=True, validation_split=VAL_SPLIT)\n",
    "\n",
    "    train_datagen = datagen.flow(x_train, y_train, batch_size=TRAIN_BATCH, subset=\"training\")\n",
    "    val_datagen = datagen.flow(x_train, y_train, batch_size=VAL_BATCH, subset=\"validation\")\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    train_steps = x_train.shape[0] * (1 - VAL_SPLIT) // TRAIN_BATCH\n",
    "    val_steps = x_train.shape[0] * VAL_SPLIT // VAL_BATCH\n",
    "    \n",
    "    history = model.fit(train_datagen, steps_per_epoch=train_steps, epochs=EPOCHS, \n",
    "                        validation_data=val_datagen, validation_steps=val_steps)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    print(loss, accuracy)\n",
    "    \n",
    "    params = {\"epochs\": EPOCHS, \"train_batch\": TRAIN_BATCH, \"val_batch\": VAL_BATCH, \"dense1\": np.nan, \"dense2\": np.nan}\n",
    "    metrics = {\"test_loss\": loss, \"test_acc\": accuracy}\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    for idx in range(len(history.history[\"loss\"])):\n",
    "        mlflow.log_metrics({'train_loss': history.history[\"loss\"][idx], 'train_acc': history.history[\"accuracy\"][idx], \n",
    "                           'val_loss': history.history[\"val_loss\"][idx], 'val_acc': history.history[\"val_accuracy\"][idx]}, step=idx+1)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfreezing last conv block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_NAME = \"conv5_block3_1_conv\"\n",
    "\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if layer.name == LAYER_NAME:\n",
    "        idx_conv_block = i\n",
    "\n",
    "for layer in model.layers[idx_conv_block:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"resnet-fine-tuning\"):\n",
    "    \n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 15\n",
    "    VAL_SPLIT = 0.1\n",
    "    LR = 1e-5\n",
    "    \n",
    "    optim = Adam(LR)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optim, metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VAL_SPLIT)\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    print(loss, accuracy)\n",
    "    \n",
    "    params = {\"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE, \"layer_name\": LAYER_NAME, \"dense1\": np.nan, \"dense2\": np.nan}\n",
    "    metrics = {\"test_loss\": loss, \"test_acc\": accuracy}\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    for idx in range(len(history.history[\"loss\"])):\n",
    "        mlflow.log_metrics({'train_loss': history.history[\"loss\"][idx], 'train_acc': history.history[\"accuracy\"][idx], \n",
    "                           'val_loss': history.history[\"val_loss\"][idx], 'val_acc': history.history[\"val_accuracy\"][idx]}, step=idx+1)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_class, y_pred_class)\n",
    "cm_df = pd.DataFrame(cm)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "# plt.savefig(\"../images/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "# model_json = model.to_json()\n",
    "# with open(\"../data/model2.json\", \"w\") as f:\n",
    "#     f.write(model_json)\n",
    "\n",
    "# model.save_weights(\"../data/weights2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
